{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특징\n",
    "- requests, BeautifulSoup 사용 X\n",
    "- table 형식의 웹페이지\n",
    "- JavaScript API를 사용하는 웹페이지 > Selenium 설치 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager # 크롬드라이버 자동 업데이트\n",
    "\n",
    "service = ChromeService(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 병합 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# result 초기화, 선언\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# 데이터를 병합해주는 함수\n",
    "def concat(a):\n",
    "    # 전역변수 선언\n",
    "    global result\n",
    "    result = pd.concat([result, a])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 별 웹페이지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력하고 싶은 최대 페이지 사용자 입력 받기\n",
    "number = int(input(\"출력하고 싶은 대외활동의 페이지 수를 쓰시오.(최대 30): \"))\n",
    "\n",
    "# 1페이지부터 30페이지까지 i 수 증가에 따라 다르게 웹페이지 링크를 가져오기\n",
    "for i in range(1,number+1):\n",
    "    driver.get(f\"https://www.all-con.co.kr/list/contest/2/{i}?sortname=cl_order&sortorder=asc&stx=&sfl=&t=2&ct=&sc=&tg=\")\n",
    "\n",
    "\n",
    "    # 대기 시간 처리 / 암시적 대기\n",
    "    driver.implicitly_wait(1) # 1초\n",
    "\n",
    "\n",
    "    # Copy full XPath를 활용하여 테이블을 table 변수에 담음\n",
    "    table = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/div[3]/table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 헤더 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 헤더\n",
    "    # table 안에서 태그 이름이 <thead>인 것을 찾아서 thead에 저장\n",
    "    thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "    # 비어있는 헤더_리스트 생성\n",
    "    theadList = []\n",
    "    for i in range(0,5):\n",
    "        thead_elements = thead.find_elements(By.TAG_NAME, 'th')[i].text\n",
    "        # 요소를 헤더_리스트에 추가\n",
    "        theadList.append(thead_elements)\n",
    "    # 웹페이지에 없는 column을 헤더_리스트에 추가\n",
    "    theadList.append(\"본문 링크\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 바디 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 컬럼 바디\n",
    "    # table 안에서 태그 이름이 <tbody>인 것을 찾아서 tbody에 저장\n",
    "    tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "    # tbody 안에서 태그 이름이 <tr>인 것을 찾아서 tr_elements에 저장\n",
    "    tr_elements = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # 비어있는 바디_리스트 생성\n",
    "    tbodyList = []\n",
    "\n",
    "    # for문 돌려서 각각의 tr요소 안에 들어 있는 대외활동 관련 정보 가져오기\n",
    "    for index, value in enumerate(tr_elements):\n",
    "        \n",
    "        # 타이틀\n",
    "        title = value.find_elements(By.TAG_NAME, \"td\")[0].text.split(\"\\n\")[0].replace(\"N\",\"\")\n",
    "        \n",
    "        # 주최\n",
    "        host = value.find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "        # 접수기한\n",
    "        date = value.find_elements(By.TAG_NAME, \"td\")[2].text\n",
    "        # 하나의 td class=\"status\" 항목 안에 <br>로 구분 되어 있음\n",
    "        # split(엔터)로 분리해서 각각의 항목을 변수에 저장\n",
    "        receiving = value.find_elements(By.TAG_NAME, \"td\")[3].text.split(\"\\n\")[0] # 접수중 여부\n",
    "        d_day = value.find_elements(By.TAG_NAME, \"td\")[3].text.split(\"\\n\")[1] # 남은 디데이\n",
    "        ongoing = receiving + ' / ' + d_day\n",
    "        # 조회수\n",
    "        hits = value.find_elements(By.TAG_NAME, \"td\")[4].text\n",
    "        # 본문 링크\n",
    "        link = value.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "        \n",
    "        # 요소를 바디_리스트에 추가\n",
    "        tbodyList.append([title, host, date, ongoing, hits, link])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # pandas로 저장\n",
    "    \n",
    "    # i가 1, 즉 1페이지일 경우 result에 바로 저장\n",
    "    if i == 1:\n",
    "        result = pd.DataFrame(data=tbodyList, columns=theadList) # 바디, 헤더 순서\n",
    "        \n",
    "    # i가 2 이상일 경우 앞선 페이지와 병합하기 위해 저장한 DataFrame을 병합 함수로 보냄 > 병합한 후 result에 저장\n",
    "    if i != 1:\n",
    "        a = pd.DataFrame(data=tbodyList, columns=theadList)\n",
    "        concat(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거 \n",
    "result_finish = result.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장/출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일로 저장\n",
    "result_finish.to_csv('allcon_result_x.xls',encoding='utf-8-sig') # .xlsx 확장자로 저장했더니 오류나고 안 열림\n",
    "\n",
    "# 최종 결과 출력\n",
    "# print(result_finish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager # 크롬드라이버 자동 업데이트\n",
    "\n",
    "service = ChromeService(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# result 초기화, 선언\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# 데이터를 병합해주는 함수\n",
    "def concat(a):\n",
    "    # 전역변수 선언\n",
    "    global result\n",
    "    result = pd.concat([result, a])\n",
    "    return\n",
    "\n",
    "number = int(input(\"출력하고 싶은 대외활동의 페이지 수를 쓰시오.(최대 30): \"))\n",
    "for i in range(1,number+1):\n",
    "    driver.get(f\"https://www.all-con.co.kr/list/contest/2/{i}?sortname=cl_order&sortorder=asc&stx=&sfl=&t=2&ct=&sc=&tg=\")\n",
    "\n",
    "\n",
    "    # 대기 시간 처리 / 암시적 대기\n",
    "    driver.implicitly_wait(1) # 1초\n",
    "\n",
    "\n",
    "    # Copy full XPath를 활용하여 테이블을 table 변수에 담음\n",
    "    table = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/div[3]/table\")\n",
    "\n",
    "\n",
    "    # 컬럼 헤더\n",
    "    thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "    theadList = []\n",
    "    for i in range(0,5):\n",
    "        thead_elements = thead.find_elements(By.TAG_NAME, 'th')[i].text\n",
    "        theadList.append(thead_elements)\n",
    "    # 웹페이지에 없는 column 추가\n",
    "    theadList.append(\"본문 링크\")\n",
    "        \n",
    "\n",
    "    # 컬럼 바디\n",
    "    tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "    tr_elements = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    tbodyList = []\n",
    "\n",
    "\n",
    "    for index, value in enumerate(tr_elements):\n",
    "        \n",
    "        # 타이틀\n",
    "        title = value.find_elements(By.TAG_NAME, \"td\")[0].text.split(\"\\n\")[0].replace(\"N\",\"\")\n",
    "        \n",
    "        # 주최\n",
    "        host = value.find_elements(By.TAG_NAME, \"td\")[1].text\n",
    "        # 접수기한\n",
    "        date = value.find_elements(By.TAG_NAME, \"td\")[2].text\n",
    "        # 하나의 td class=\"status\" 항목 안에 <br>로 구분 되어 있음\n",
    "        # split(엔터)로 분리해서 각각의 항목을 변수에 저장\n",
    "        receiving = value.find_elements(By.TAG_NAME, \"td\")[3].text.split(\"\\n\")[0] # 접수중 여부\n",
    "        d_day = value.find_elements(By.TAG_NAME, \"td\")[3].text.split(\"\\n\")[1] # 남은 디데이\n",
    "        ongoing = receiving + ' / ' + d_day\n",
    "        # 조회수\n",
    "        hits = value.find_elements(By.TAG_NAME, \"td\")[4].text\n",
    "        # 본문 링크\n",
    "        link = value.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "        \n",
    "        \n",
    "        tbodyList.append([title, host, date, ongoing, hits, link])\n",
    "    \n",
    "\n",
    "\n",
    "    # pandas로 저장\n",
    "    \n",
    "    if i == 1:\n",
    "        result = pd.DataFrame(data=tbodyList, columns=theadList) # 바디, 헤더 순서\n",
    "    if i != 1:\n",
    "        a = pd.DataFrame(data=tbodyList, columns=theadList)\n",
    "        concat(a)\n",
    "    # result.to_csv('allcon_result_x.xls',encoding='utf-8-sig') # 엑셀 파일로 저장\n",
    "    # result.to_csv('allcon_result_c.csv',index=False,encoding='utf-8-sig') # csv 파일로 저장\n",
    "    \n",
    "# 중복제거 \n",
    "result_finish = result.drop_duplicates()\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "result_finish.to_csv('allcon_result_x.xls',encoding='utf-8-sig')\n",
    "\n",
    "# print(result_finish)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
